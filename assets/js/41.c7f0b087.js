(window.webpackJsonp=window.webpackJsonp||[]).push([[41],{1306:function(s,t,a){"use strict";a.r(t);var n=a(0),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,n=s._self._c||t;return n("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[n("p",[n("strong",[s._v("关于序列化器里的上下文")])]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" ser的context上下文在Field类的context方法里"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("从这里开始分析!"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Field")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),n("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[s._v("@property")]),s._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("root")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        root "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),s._v(" root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parent "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("is")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            root "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("parent\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" root\n      \n      "),n("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[s._v("@property")]),s._v("\n      "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("context")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n          "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("getattr")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("root"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'_context'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        \n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 在BaseSerializer的__init__里有这行代码"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("意味着序列化器类的实例可以传context参数!!\n  self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_context "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'context'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ★ 看到没,一开始它就是个字典!")]),s._v("\n  eg"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" 阅读视图类GenericAPIView的get_serializer方法的源码"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("该方法中的context上下文就是这样使用的!!!\n    \n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 如何使用呢?伪代码如下"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 序列化器类里")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("LoginSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Meta")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        model "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("User\n        fields "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'username'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'password'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("validate")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" attrs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        token "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"..."')]),s._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'token'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" token  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ★★★ 给context字典赋值")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" attrs\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 视图类里")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("LoginView")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ViewSet"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("login")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        ser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("LoginSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_valid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            token "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("context"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'token'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ★★★ 在context字典中取值")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br")])]),n("p",[n("strong",[s._v("另外需注意的点")])]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("validated_data 是在ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_valid 校验通过后使用的"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" 若在钩子函数中使用ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("validated_data 会报错!!\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 若想在某个字段钩子函数中使用上一个字段钩子校验通过的值"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("可以从 ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("initial_data中取到上一个字段的值!!\n  虽然ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("initial_data是前端传过来的原始数据"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("但能执行到某个字段的钩子"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("那么证明上一个字段的校验肯定通过了的"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  所以直接用ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("initial_data里面那么“对应上一个字段”的值"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("是没有任何问题的!\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br")])]),n("hr"),s._v(" "),n("h2",{attrs:{id:"序列化demo"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#序列化demo"}},[s._v("#")]),s._v(" 序列化Demo")]),s._v(" "),n("h3",{attrs:{id:"示例代码"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#示例代码"}},[s._v("#")]),s._v(" 示例代码")]),s._v(" "),n("p",[n("img",{attrs:{src:a(335),alt:"image-20231103152802983"}})]),s._v(" "),n("h3",{attrs:{id:"添加实验数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#添加实验数据"}},[s._v("#")]),s._v(" 添加实验数据")]),s._v(" "),n("blockquote",[n("p",[s._v("你把ORM表给ChatGpt, 它会自动帮你生成, 哈哈哈哈!太省事了.")])]),s._v(" "),n("p",[n("img",{attrs:{src:a(824),alt:"image-20231103154354761"}})]),s._v(" "),n("h3",{attrs:{id:"数据库数据"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#数据库数据"}},[s._v("#")]),s._v(" 数据库数据")]),s._v(" "),n("p",[n("img",{attrs:{src:a(825),alt:"image-20231103153221861"}})]),s._v(" "),n("h3",{attrs:{id:"实验结果"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#实验结果"}},[s._v("#")]),s._v(" 实验结果")]),s._v(" "),n("blockquote",[n("p",[s._v("查询一条数据, 这样写接口是不规范的.. 但这里不是重点探究这个,将就下吧.")])]),s._v(" "),n("p",[n("img",{attrs:{src:a(826),alt:"image-20231103153757115"}})]),s._v(" "),n("hr"),s._v(" "),n("h2",{attrs:{id:"序列化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#序列化"}},[s._v("#")]),s._v(" 序列化")]),s._v(" "),n("blockquote",[n("p",[s._v("每一步详细的源码过程可以翻阅 序列化源码.md !!")])]),s._v(" "),n("p",[s._v("我只能说, 总结的很完美!! 哈哈哈哈哈.")]),s._v(" "),n("p",[n("img",{attrs:{src:a(335),alt:"image-20231103152802983"}})]),s._v(" "),n("p",[n("strong",[s._v("下方是单条数据序列化的流程图!!")])]),s._v(" "),n("p",[n("img",{attrs:{src:a(827),alt:"image-20231103224507673"}})]),s._v(" "),n("p",[n("em",[s._v("详细说明如下:")])]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.")]),s._v(" 创建字段对象 \n   "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" _creation_counter 计数器\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2.")]),s._v(" 元类创建序列化器类 \n   "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 剔除 类成员“字段类型的类变量” 加到 新增的类成员_declared_fields中"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" 其余类成员Meta等不变\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3.")]),s._v(" 序列化器类实例化创建对象\n   "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("instance many "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" UserSerializer类的实例\n   "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("queryset many "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" ListSerializer类的实例"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("该实例有成员UserSerializer类的实例!!\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("4.")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data开始序列化 以单条数据为例 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("下面总结顺序跟看源码的流程相反"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("逆向思维"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("更容易理解"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" @cached_property   ★ 该方法被它装饰了哦!!\n   ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fields         获取所有经过bind处理后的字段对象\n   "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get_fields 获得所有字段对象\n        注"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" 在获取所有字段对象阶段"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" 你序列化器类里定义了啥字段类型的类变量都可以"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("都不会报错"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get_field_names 获取所有的字段名 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("请翻阅"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("该小节总结的规则"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n         特地说下filed和exclude\n         "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" filed "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("类变量名些“必须写进来”、ORM表中的字段名 无其他选择"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" exclude "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ORM表中的一些字段名"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("需排除通过类变量重写的字段名"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 无其他选择\n         ★ ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get_field_names返回的字段名集合 必定 小于等于"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("包含于等于 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("字段类型的类变量"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("ORM表中的字段名"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" 将上一步获得的字段名分为两组 注"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("第一组优先级高于第二组"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("因为类变量可能会跟ORM表中的字段名重名"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 第一组"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" 字段类型的类变量 保留该字段对象\n         "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 第二组"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ORM表中的字段名 db匹配自动创建字段对象 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("PS"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("ORM表中字段的verbose_name对应创建的字段对象的label属性"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" bind 将所有字段对象经过bind处理\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" bind操作 处理字段对象的一些属性 field_name、parent、label、source、source_attrs\n         "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 如何处理的? "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("请翻阅"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("该小节总结的规则"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_readable_fields 筛选出"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" write_only"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("即可序列化的字段对象\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" 对筛选后的这些字段对象进行循环\n   ret "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" OrderedDict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" field "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" fields"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n       "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# eg1: attribute = <UserInfo object>.depart.title")]),s._v("\n       "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# eg2: attribute = instance")]),s._v("\n       "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 特别注意,它使用的是source_attrs !!!")]),s._v("\n       attribute "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get_attribute"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 得到的结果 可能是数据库中字段对应的值、也可能是instance一条记录.")]),s._v("\n       "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v('# eg1: ret["depart"] = str(<UserInfo object>.depart.title)')]),s._v("\n       "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v('# eg2: ret["Xxx"] = SerializerMethodField().to_representation(instance)')]),s._v("\n       ret"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("field_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("to_representation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("attribute"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 需要特别注意的是 SerializerMethodField 类型的字段对象!!序列化的自定义字段绑定的方法的value参数是数据库中的一条记录"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" 若是多条数据"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("就多了个循环"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("注意ListSerializer类的实例里child成员!!\n\n\n\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get_fields的结果"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("返回值 "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"获得的所有字段对象"')]),s._v("\nOrderedDict"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'id'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("label"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'ID'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" read_only"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'gender'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("source"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'get_gender_display'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'depart'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("source"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'depart.title'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'ctime'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" DateTimeField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("format")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'%Y-%m-%d'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'xxx'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" SerializerMethodField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'tag'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" SerializerMethodField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("label"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'姓名'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("32")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'age'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("label"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'年龄'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n  \n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fields的结果"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("返回值 "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"经过bind处理后的所有字段对象"')]),s._v(" “字段对象里的field_name就是字段名!”\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'id'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("label"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'ID'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" read_only"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n   "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'gender'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("source"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'get_gender_display'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n   "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'depart'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("source"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'depart.title'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n   "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'ctime'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" DateTimeField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("format")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'%Y-%m-%d'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n   "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'xxx'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" SerializerMethodField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n   "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'tag'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" SerializerMethodField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n   "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("label"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'姓名'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("32")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("  \n   "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'age'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("label"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'年龄'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n你别看上面打印的结果没啥改变"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("循环打印每个字段对象中的这些属性field_name、label、source、source_attrs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("就原形毕露了!\n（PS"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("打印字段对象的parent属性会一直递归"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("不知啥原因"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("暂且不管"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("）\nIntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("label"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'ID'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" read_only"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("id")]),s._v(" ID "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("id")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'id'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\nCharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("source"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'get_gender_display'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("    gender Gender get_gender_display "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'get_gender_display'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\nCharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("source"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'depart.title'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("          depart Depart depart"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("title "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'depart'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'title'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\nDateTimeField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("format")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'%Y-%m-%d'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("          ctime Ctime ctime "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'ctime'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\nSerializerMethodField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("                   xxx Xxx "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\nSerializerMethodField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("                   tag Tag "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\nCharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("label"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'姓名'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("32")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("     name 姓名 name "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\nIntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("label"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'年龄'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("                 age 年龄 age "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'age'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br"),n("span",{staticClass:"line-number"},[s._v("45")]),n("br"),n("span",{staticClass:"line-number"},[s._v("46")]),n("br"),n("span",{staticClass:"line-number"},[s._v("47")]),n("br"),n("span",{staticClass:"line-number"},[s._v("48")]),n("br"),n("span",{staticClass:"line-number"},[s._v("49")]),n("br"),n("span",{staticClass:"line-number"},[s._v("50")]),n("br"),n("span",{staticClass:"line-number"},[s._v("51")]),n("br"),n("span",{staticClass:"line-number"},[s._v("52")]),n("br"),n("span",{staticClass:"line-number"},[s._v("53")]),n("br"),n("span",{staticClass:"line-number"},[s._v("54")]),n("br"),n("span",{staticClass:"line-number"},[s._v("55")]),n("br"),n("span",{staticClass:"line-number"},[s._v("56")]),n("br"),n("span",{staticClass:"line-number"},[s._v("57")]),n("br"),n("span",{staticClass:"line-number"},[s._v("58")]),n("br"),n("span",{staticClass:"line-number"},[s._v("59")]),n("br"),n("span",{staticClass:"line-number"},[s._v("60")]),n("br"),n("span",{staticClass:"line-number"},[s._v("61")]),n("br"),n("span",{staticClass:"line-number"},[s._v("62")]),n("br"),n("span",{staticClass:"line-number"},[s._v("63")]),n("br"),n("span",{staticClass:"line-number"},[s._v("64")]),n("br"),n("span",{staticClass:"line-number"},[s._v("65")]),n("br"),n("span",{staticClass:"line-number"},[s._v("66")]),n("br"),n("span",{staticClass:"line-number"},[s._v("67")]),n("br"),n("span",{staticClass:"line-number"},[s._v("68")]),n("br"),n("span",{staticClass:"line-number"},[s._v("69")]),n("br"),n("span",{staticClass:"line-number"},[s._v("70")]),n("br"),n("span",{staticClass:"line-number"},[s._v("71")]),n("br"),n("span",{staticClass:"line-number"},[s._v("72")]),n("br"),n("span",{staticClass:"line-number"},[s._v("73")]),n("br"),n("span",{staticClass:"line-number"},[s._v("74")]),n("br")])]),n("hr"),s._v(" "),n("h2",{attrs:{id:"验证-存储"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#验证-存储"}},[s._v("#")]),s._v(" 验证+存储")]),s._v(" "),n("p",[n("img",{attrs:{src:a(828),alt:"image-20231109151219177"}})]),s._v(" "),n("p",[n("strong",[s._v("来抓一抓错误")])]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ValidationError")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("APIException"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    status_code "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" status"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("HTTP_400_BAD_REQUEST\n    default_detail "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Invalid input.'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    default_code "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'invalid'")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 看到没,detail可以位置传参传过去!")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("__init__")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" detail"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" code"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" detail "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("is")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            detail "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("default_detail\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" code "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("is")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            code "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("default_code\n\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("detail"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("tuple")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            detail "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("list")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("detail"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("elif")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("detail"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("dict")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("and")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("detail"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("list")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            detail "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("detail"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("detail "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" _get_error_details"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("detail"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" code"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n先看图中的右下角的run_validators函数"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" errors"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" 字段自身的校验"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("有多个规则不满足"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("不满足的都会收集到\n然后该函数 "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("raise")]),s._v(" ValidationError"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("errors"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 在Serializer类中的to_internal_value被捕获\n特别注意的是"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" errors"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("field_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" exc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("detail  ★看到没"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("错误信息的key是字段名!! 而且"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("try")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("except")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("处于"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v("循环里"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n最后"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("与"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("raise")]),s._v(" ValidationError"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("errors"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 在BaseSerializer类中的is_valid被捕获\nSo"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("举个例子"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("字段自身校验不通过"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("errors的值像这个样子"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'mobile'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("ErrorDetail"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("string"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'该字段不能为空。'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" code"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'blank'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" \n   "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'password'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("ErrorDetail"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("string"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'该字段不能为空。'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" code"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'blank'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n只不过"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("后端通过Response处理后返回给前端"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("前端拿到的是 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'mobile'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'该字段不能为空。'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'password'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'该字段不能为空。'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n那关于全局钩子中的报错呢?你看源码"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("关键在于这行语句\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("raise")]),s._v(" ValidationError"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("detail"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("as_serializer_error"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("exc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 细看as_serializer_error\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("as_serializer_error")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("exc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("assert")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("exc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ValidationError"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" DjangoValidationError"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("exc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" DjangoValidationError"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        detail "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" get_error_detail"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("exc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        detail "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" exc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("detail\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("detail"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Mapping"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" value "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("list")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Mapping"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" key"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" detail"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("items"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("elif")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("detail"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("list")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            api_settings"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("NON_FIELD_ERRORS_KEY"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" detail  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ★★★")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n        api_settings"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("NON_FIELD_ERRORS_KEY"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("detail"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ★★★")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br"),n("span",{staticClass:"line-number"},[s._v("45")]),n("br"),n("span",{staticClass:"line-number"},[s._v("46")]),n("br"),n("span",{staticClass:"line-number"},[s._v("47")]),n("br"),n("span",{staticClass:"line-number"},[s._v("48")]),n("br"),n("span",{staticClass:"line-number"},[s._v("49")]),n("br"),n("span",{staticClass:"line-number"},[s._v("50")]),n("br"),n("span",{staticClass:"line-number"},[s._v("51")]),n("br")])]),n("p",[n("strong",[s._v("值得注意的点:")])]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 若ORM表中写了这样的字段\n    ext1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("verbose_name"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"格外1"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" blank"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" null"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    ext2 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("verbose_name"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"格外2"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" blank"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" null"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  ★ 通过db匹配后"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("会自动生成的这样的字段对象"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" !!\n    CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("allow_blank"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" allow_null"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" label"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'格外1'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" required"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("allow_null"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" label"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'格外2'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" required"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    看到没"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("required"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),s._v("意味检验的话"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("前端不是必传"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n    另外生成的字段对象的default值为"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'rest_framework.fields.empty'")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n  ★ 经过ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data序列化后"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("ext1和ext2字段值的结果都是null\n  关于这个"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("有点模糊不清"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("做项目时再探究"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("可先看下官方文档"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  https"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("//")]),s._v("q1mi"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("github"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("io"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("Django"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("REST"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("framework"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("documentation"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("api"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("guide"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("fields_zh"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#allow_null")]),s._v("\n  https"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("//")]),s._v("q1mi"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("github"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("io"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("Django"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("REST"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("framework"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("documentation"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("api"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("guide"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("fields_zh"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#charfield")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 若序列化器类写了额外字段 more "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("default"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"默认"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  那么经过__init__实例化后"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("该字段required"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("default"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"默认"')]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 若ORM表中写了这样的字段\n  ext3 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("verbose_name"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"格外3"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("default"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("25")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  ★ 通过db匹配后"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("会自动生成的这样的字段对象"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" !!\n  IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("label"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'格外3'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" required"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 另我很疑惑的是"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("其default值是 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'rest_framework.fields.empty'")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n  \n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" save操作\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("create")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        book "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("objects"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("create"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" book\n      \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("update")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'price'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("price"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("publish "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'publish'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("publish"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("save"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" instance \n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br")])]),n("hr"),s._v(" "),n("h2",{attrs:{id:"验证-存储-序列化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#验证-存储-序列化"}},[s._v("#")]),s._v(" 验证+存储+序列化")]),s._v(" "),n("p",[n("img",{attrs:{src:a(829),alt:"image-20231109151435224"}})]),s._v(" "),n("p",[n("img",{attrs:{src:a(830),alt:"image-20231112200414491"}})]),s._v(" "),n("p",[n("font",{attrs:{color:"gray"}},[s._v("Ps: 上图的更新还有个奇淫技巧 "),n("code",[s._v("instance.__dict__.update(**validated_data)")])])],1),s._v(" "),n("p",[n("strong",[s._v("分析下整体过程")])]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[s._v("序列化器中类变量以及Meta中写的那些字段"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("只能决定 有哪些字段对象可以拿来用"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\nread_only和write_only才决定了哪些字段拿来序列化"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("哪些拿来验证"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v(" 拿来验证的字段才是必须要传的!\n\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.")]),s._v("纯序列化单条记录 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" \nser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ExampleModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \nser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data\n\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2.")]),s._v("纯序列化多条记录"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("\nser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ExampleModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("queryset"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("many"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data\n\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3.")]),s._v("验证前端传递的数据 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 保存数据库 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 序列化 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("\nser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ExampleModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \nser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_valid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  \nser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data\n\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("4.")]),s._v("验证前端传递的数据 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 更新数据库 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 序列化 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("\nser ExampleModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_valid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  \nser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data\n\n\n【壹壹壹】\n上述的"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("种情况"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("无论哪一种"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("都会先经历三步!\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" 创建字段对象\n   以前字典是无序的"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("所以里面有个计数器"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("表明先后创建的顺序"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" 基于元类创建序列化器类\n   "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'_declared_fields'")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("IntegerField字段对象"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'age'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("CharField字段对象"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n   注意其key值是类变量的变量名"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("value值是该类变量名对应的值"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" 创建序列化器的对象\n   主要是根据many"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),s._v("和many"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),s._v("创建的对象不同"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("毕竟new方法返回啥"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("该实例对象就是啥"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n   ExampleModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("or")]),s._v("  ListSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("child"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("ExampleModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\n【贰贰贰】\nok"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("前面三步进行完后"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("会执行ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data或者ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_valid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("我们继续寻找共同点!\n只要是执行ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data或者执行ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_valid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("都会经历这三步"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n★★★ 本质就是在执行Serializer类中被@cached_property装饰的fields方法!!\n    "),n("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[s._v("@cached_property")]),s._v("会将fields方法的执行结果放到ser的__dict__中"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" 即ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("__dict__"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"fields"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" 结果\n\t\t★★★ So"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_valid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("后再ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("不会再执行一遍 以下三步"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("fields方法! 而是会直接去__dict__中取"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" 获得所有的字段名field_names "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" 获取序列化器类中类变量的变量名 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" 序列化器类使用的model表中的所有字段名\n   注意"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" \n      若写"),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"__all__"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("是 类变量名 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" db中字段名"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" field_names列表中"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("还有可能重复\n      若fields指定了字段"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("那么额外字段得写在里面"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("因为 field_names列表就是fields的值"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" 会循环field_names获得所有的字段对象 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" \n         "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'_declared_fields'")]),s._v("中的字段对象原封不动 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" 匹配数据库自动创建的字段对象"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("注"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("字段名与类变量重复了不会匹配创建"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   所有字段对象 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'类变量变量名'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("字段对象"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'数据库中的字段名'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("匹配自动创建字段对象"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" 会循环所有字段对象"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("执行Field类里的bind方法! \n   bind"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" field_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" parent"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("   field_name就是循环的每一项的key值"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("parent就是序列化器类实例\n   "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 关于字段对象里的成员 field_name 等于 key值"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("就是字段名\n   "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 关于字段对象里的成员 source\n     "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 字段对象有source的 source值不变\n     "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 字段对象有没有设置source的 字段对象的source等于field_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("即字段名\n   "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 关于字段对象里的成员 source_attrs\n     "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" source_attrs "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" source"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("split"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'.'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n       "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'depart.title'")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'depart'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'title'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'get_gender_display'")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"get_gender_display"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n      \n      \nok"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("经过上述流程"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("提醒一点序列化器类实例化时候传入的 instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("data 里实参都还没有咋使用"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n              只是序列化器类实例的实例里躺着两个成员 self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance 和 self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("initial_data\n\n  \n\n开始分情况讨论\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" 情况"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("纯序列化 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" 注"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("无论单条还是多条数据"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("本质都是一样的"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v(" 假如"),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"instance是UserInfo表的一条记录<UserInfo object>"')]),s._v("\n  ser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ExampleModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 1")]),s._v("\n  ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 2")]),s._v("\n  \n  ○ 执行第"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("条语句ser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ExampleModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("时先执行【壹壹壹】\n  ○ 执行第"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("条语句时ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data先执行【贰贰贰】"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" 接着\n  step1"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" 接着"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("会再次循环所有字段对象"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" 不要write_only"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),s._v("的字段对象"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n         得到可用于序列化的字段对象 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("字段对象"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("字段对象"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("字段对象"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3.")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n  step2"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" 接着"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("循环 可用于序列化的字段对象 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("字段对象"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("字段对象"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("字段对象"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3.")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n         关键在于执行两行代码"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""假比,instance是UserInfo表的一条记录<UserInfo object>,该表的Fk字段depart,有choice属性的字段gender\n         ret["depart"] = str(<UserInfo object>.depart.title)\n         ret["gender"] = str(<UserInfo object>.get_gender_display())\n         """')]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" attribute "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get_attribute"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" ret"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("field_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("to_representation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("attribute"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" 情况"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("验证前端传递的数据 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 保存数据库 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 序列化 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("  \n  ser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ExampleModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 1")]),s._v("\n  ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_valid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 2")]),s._v("\n  ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3")]),s._v("\n  \n  ○ 执行第"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("条语句ser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" ExampleModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("时先执行【壹壹壹】\n  ○ 执行第"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("条语句时ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_valid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("先执行【贰贰贰】"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("接着\n  step1"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" 接着"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("会再次循环所有字段对象"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" 不要read_only"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),s._v("的字段对象"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n         得到可用于验证的字段对象 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("字段对象"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("字段对象"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("字段对象"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3.")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n  step2"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" 字段对象 "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" 可用于验证的字段对象 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("字段对象"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("字段对象"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("字段对象"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3.")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n             先会通过伪代码 value "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("field_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" 拿到当前字段对象在前端传递的Json数据中对应的值!\n             校验字段自己的规则 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 检验成功"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("返回value\n             执行字段的钩子函数 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 上一步返回的value传递给字段钩子函数"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("检验成功"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("返回value\n             在最后"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("执行了set_value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ret"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("source_attrs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n         上述过程"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("相当于 有个字典validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("每次循环都会执行 validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("source_attrs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" value\n  step3"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" 执行全局钩子函数 其参数是validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 校验通过"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("返回的也是validated_data\n  step4"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" 执行save"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 也就是执行 self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("  self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("create"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n         ★ 注意啊！self是ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("所以ser中的instance成员有值啦!!!\n  就此"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("验证并存储数据库执行完毕\n  ○ 执行第"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("条语句ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data时不会重新执行"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("贰贰贰"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("它直接拿到ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_valid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("执行"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("贰贰贰"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("时的结果!\n  step5"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" 开始 情况"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" 纯序列化中的 第一步和第二步"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n  \n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" 情况"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("验证前端传递的数据 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 更新数据库 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 序列化 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("\n  ser ExampleModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 1")]),s._v("\n  ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_valid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 2")]),s._v("\n  ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3")]),s._v("\n  \n  其实与情况"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("整体并无不同"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("仅仅只是在save时候\n                      是self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("update"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n  也就是说"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("传入的instance只是在更新数据的时候使用了下!! \n  后续执行ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data时使用的是 重新赋值后的 self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance!\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br"),n("span",{staticClass:"line-number"},[s._v("45")]),n("br"),n("span",{staticClass:"line-number"},[s._v("46")]),n("br"),n("span",{staticClass:"line-number"},[s._v("47")]),n("br"),n("span",{staticClass:"line-number"},[s._v("48")]),n("br"),n("span",{staticClass:"line-number"},[s._v("49")]),n("br"),n("span",{staticClass:"line-number"},[s._v("50")]),n("br"),n("span",{staticClass:"line-number"},[s._v("51")]),n("br"),n("span",{staticClass:"line-number"},[s._v("52")]),n("br"),n("span",{staticClass:"line-number"},[s._v("53")]),n("br"),n("span",{staticClass:"line-number"},[s._v("54")]),n("br"),n("span",{staticClass:"line-number"},[s._v("55")]),n("br"),n("span",{staticClass:"line-number"},[s._v("56")]),n("br"),n("span",{staticClass:"line-number"},[s._v("57")]),n("br"),n("span",{staticClass:"line-number"},[s._v("58")]),n("br"),n("span",{staticClass:"line-number"},[s._v("59")]),n("br"),n("span",{staticClass:"line-number"},[s._v("60")]),n("br"),n("span",{staticClass:"line-number"},[s._v("61")]),n("br"),n("span",{staticClass:"line-number"},[s._v("62")]),n("br"),n("span",{staticClass:"line-number"},[s._v("63")]),n("br"),n("span",{staticClass:"line-number"},[s._v("64")]),n("br"),n("span",{staticClass:"line-number"},[s._v("65")]),n("br"),n("span",{staticClass:"line-number"},[s._v("66")]),n("br"),n("span",{staticClass:"line-number"},[s._v("67")]),n("br"),n("span",{staticClass:"line-number"},[s._v("68")]),n("br"),n("span",{staticClass:"line-number"},[s._v("69")]),n("br"),n("span",{staticClass:"line-number"},[s._v("70")]),n("br"),n("span",{staticClass:"line-number"},[s._v("71")]),n("br"),n("span",{staticClass:"line-number"},[s._v("72")]),n("br"),n("span",{staticClass:"line-number"},[s._v("73")]),n("br"),n("span",{staticClass:"line-number"},[s._v("74")]),n("br"),n("span",{staticClass:"line-number"},[s._v("75")]),n("br"),n("span",{staticClass:"line-number"},[s._v("76")]),n("br"),n("span",{staticClass:"line-number"},[s._v("77")]),n("br"),n("span",{staticClass:"line-number"},[s._v("78")]),n("br"),n("span",{staticClass:"line-number"},[s._v("79")]),n("br"),n("span",{staticClass:"line-number"},[s._v("80")]),n("br"),n("span",{staticClass:"line-number"},[s._v("81")]),n("br"),n("span",{staticClass:"line-number"},[s._v("82")]),n("br"),n("span",{staticClass:"line-number"},[s._v("83")]),n("br"),n("span",{staticClass:"line-number"},[s._v("84")]),n("br"),n("span",{staticClass:"line-number"},[s._v("85")]),n("br"),n("span",{staticClass:"line-number"},[s._v("86")]),n("br"),n("span",{staticClass:"line-number"},[s._v("87")]),n("br"),n("span",{staticClass:"line-number"},[s._v("88")]),n("br"),n("span",{staticClass:"line-number"},[s._v("89")]),n("br"),n("span",{staticClass:"line-number"},[s._v("90")]),n("br"),n("span",{staticClass:"line-number"},[s._v("91")]),n("br"),n("span",{staticClass:"line-number"},[s._v("92")]),n("br"),n("span",{staticClass:"line-number"},[s._v("93")]),n("br"),n("span",{staticClass:"line-number"},[s._v("94")]),n("br"),n("span",{staticClass:"line-number"},[s._v("95")]),n("br"),n("span",{staticClass:"line-number"},[s._v("96")]),n("br"),n("span",{staticClass:"line-number"},[s._v("97")]),n("br"),n("span",{staticClass:"line-number"},[s._v("98")]),n("br"),n("span",{staticClass:"line-number"},[s._v("99")]),n("br"),n("span",{staticClass:"line-number"},[s._v("100")]),n("br"),n("span",{staticClass:"line-number"},[s._v("101")]),n("br"),n("span",{staticClass:"line-number"},[s._v("102")]),n("br"),n("span",{staticClass:"line-number"},[s._v("103")]),n("br"),n("span",{staticClass:"line-number"},[s._v("104")]),n("br"),n("span",{staticClass:"line-number"},[s._v("105")]),n("br"),n("span",{staticClass:"line-number"},[s._v("106")]),n("br"),n("span",{staticClass:"line-number"},[s._v("107")]),n("br"),n("span",{staticClass:"line-number"},[s._v("108")]),n("br"),n("span",{staticClass:"line-number"},[s._v("109")]),n("br"),n("span",{staticClass:"line-number"},[s._v("110")]),n("br"),n("span",{staticClass:"line-number"},[s._v("111")]),n("br"),n("span",{staticClass:"line-number"},[s._v("112")]),n("br"),n("span",{staticClass:"line-number"},[s._v("113")]),n("br")])]),n("p",[s._v("★★★ 粘贴一下非常重要的源码.")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BaseSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("__init__")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("empty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" instance\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" data "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("is")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" empty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("initial_data "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" data\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("partial "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'partial'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_context "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'context'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'many'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("super")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("__init__"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("__new__")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("cls"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pop"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'many'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# - 决定了序列化器类实例化时返回的实例是什么.")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" cls"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("many_init"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("super")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("__new__"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("cls"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        \n    "),n("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[s._v("@property")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("data")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("hasattr")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'_data'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("is")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("and")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("getattr")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'_errors'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ser=A(instance=instance) ser.data")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ser=A(data=request.data) - ser.is_valid() -  save() - ser.data")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ser=A(data=request.data,instance=instance) -  ser.is_valid() - save() - ser.data")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 上面三个流程,执行ser.data时,都会执行这里.")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 只不过,self.instance不一样,分别是 传入的/新增的/更新的! 因为运行save时,将结果赋值给了self.instance.")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# - ★ 跳转到Serializer的to_representation方法 里面有条重要语句 fields = self._readable_fields !!!")]),s._v("\n                self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_data "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("to_representation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("elif")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("hasattr")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'_validated_data'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("and")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("getattr")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'_errors'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ser=A(data=request.data) ser.is_valid() 没有save 直接ser.data时执行!!")]),s._v("\n                self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_data "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("to_representation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 其余情况 比如: ser=A() ser.data")]),s._v("\n                self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_data "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get_initial"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_data\n      \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("is_valid")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" raise_exception"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# - 注意,重复多次校验,只会走一次")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("hasattr")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'_validated_data'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("try")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# - ★ 开始校验 跳转到Serializer的run_validation方法")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     里面有个重要语句 self.to_internal_value(data) ")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#                    - 然后在to_internal_value方法中,fields = self._writable_fields!!!")]),s._v("\n                self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_validated_data "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("run_validation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("initial_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("except")]),s._v(" ValidationError "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" exc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_validated_data "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n                self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_errors "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" exc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("detail\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_errors "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_errors "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("and")]),s._v(" raise_exception"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("raise")]),s._v(" ValidationError"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("errors"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("bool")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_errors"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("save")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        validated_data "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ★该self就是ser,给ser.instance赋值啦!!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("is")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("update"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 更新")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("assert")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("is")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'`update()` did not return an object instance.'")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("create"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 新增")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("assert")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("is")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'`create() did not return an object instance.'")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance\n      \n    "),n("span",{pre:!0,attrs:{class:"token decorator annotation punctuation"}},[s._v("@property")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("validated_data")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("hasattr")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'_validated_data'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            msg "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'You must call `.is_valid()` before accessing `.validated_data`.'")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("raise")]),s._v(" AssertionError"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("msg"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_validated_data  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#  返回所有校验通过的前端传递的数据 ")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br"),n("span",{staticClass:"line-number"},[s._v("45")]),n("br"),n("span",{staticClass:"line-number"},[s._v("46")]),n("br"),n("span",{staticClass:"line-number"},[s._v("47")]),n("br"),n("span",{staticClass:"line-number"},[s._v("48")]),n("br"),n("span",{staticClass:"line-number"},[s._v("49")]),n("br"),n("span",{staticClass:"line-number"},[s._v("50")]),n("br"),n("span",{staticClass:"line-number"},[s._v("51")]),n("br"),n("span",{staticClass:"line-number"},[s._v("52")]),n("br"),n("span",{staticClass:"line-number"},[s._v("53")]),n("br"),n("span",{staticClass:"line-number"},[s._v("54")]),n("br"),n("span",{staticClass:"line-number"},[s._v("55")]),n("br"),n("span",{staticClass:"line-number"},[s._v("56")]),n("br"),n("span",{staticClass:"line-number"},[s._v("57")]),n("br"),n("span",{staticClass:"line-number"},[s._v("58")]),n("br"),n("span",{staticClass:"line-number"},[s._v("59")]),n("br"),n("span",{staticClass:"line-number"},[s._v("60")]),n("br"),n("span",{staticClass:"line-number"},[s._v("61")]),n("br"),n("span",{staticClass:"line-number"},[s._v("62")]),n("br"),n("span",{staticClass:"line-number"},[s._v("63")]),n("br"),n("span",{staticClass:"line-number"},[s._v("64")]),n("br"),n("span",{staticClass:"line-number"},[s._v("65")]),n("br"),n("span",{staticClass:"line-number"},[s._v("66")]),n("br"),n("span",{staticClass:"line-number"},[s._v("67")]),n("br"),n("span",{staticClass:"line-number"},[s._v("68")]),n("br"),n("span",{staticClass:"line-number"},[s._v("69")]),n("br"),n("span",{staticClass:"line-number"},[s._v("70")]),n("br"),n("span",{staticClass:"line-number"},[s._v("71")]),n("br"),n("span",{staticClass:"line-number"},[s._v("72")]),n("br"),n("span",{staticClass:"line-number"},[s._v("73")]),n("br"),n("span",{staticClass:"line-number"},[s._v("74")]),n("br"),n("span",{staticClass:"line-number"},[s._v("75")]),n("br")])]),n("hr"),s._v(" "),n("p",[n("strong",[s._v("方法的参数、返回值; 当前self是谁, 赋值操作时, 给它添加了啥成员;@cached_property; 这些就是我此次梳理源码后的心得!!")])]),s._v(" "),n("hr")])}),[],!1,null,null,null);t.default=e.exports},335:function(s,t,a){s.exports=a.p+"assets/img/image-20231103152802983.97198093.png"},824:function(s,t,a){s.exports=a.p+"assets/img/image-20231103154354761.78abcaa6.png"},825:function(s,t,a){s.exports=a.p+"assets/img/image-20231103153221861.d6f871df.png"},826:function(s,t,a){s.exports=a.p+"assets/img/image-20231103153757115.b33e9a84.png"},827:function(s,t,a){s.exports=a.p+"assets/img/image-20231103224507673.e301c233.png"},828:function(s,t,a){s.exports=a.p+"assets/img/image-20231109151219177.f4e6f639.png"},829:function(s,t,a){s.exports=a.p+"assets/img/image-20231109151435224.7886f5bd.png"},830:function(s,t,a){s.exports=a.p+"assets/img/image-20231112200414491.681e2593.png"}}]);