(window.webpackJsonp=window.webpackJsonp||[]).push([[40],{1281:function(s,t,a){"use strict";a.r(t);var n=a(0),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,n=s._self._c||t;return n("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[n("p",[n("font",{attrs:{color:"red"}},[s._v("!!本篇将阐述序列化类Serializer的使用!!")]),n("br"),s._v("\n我们从数据库中查出来的对象是queryset对象或者是模型类的一个实例对象,我们需要将其字典格式的数据序列化提供给前端用."),n("br"),s._v("\n序列化的过程可以自己写,也可以用序列化类Serializer来实现!! 反序列化的过程同理,也可以借助序列化类实现!")],1),s._v(" "),n("h2",{attrs:{id:"基础"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#基础"}},[s._v("#")]),s._v(" 基础")]),s._v(" "),n("h3",{attrs:{id:"基本使用-序列化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#基本使用-序列化"}},[s._v("#")]),s._v(" 基本使用(序列化)")]),s._v(" "),n("blockquote",[n("p",[s._v("Postman Get请求输入地址 "),n("code",[s._v("http://127.0.0.1:8000/books/")]),s._v(" "),n("strong",[s._v("获取所有图书")]),n("br"),s._v("\n返回结果 "),n("code",[s._v('[{"name":"红楼梦","price":"11","publish":"北京出版社"}]')])]),s._v(" "),n("p",[s._v("Postman Get请求输入地址 "),n("code",[s._v("http://127.0.0.1:8000/books/1")]),s._v(" "),n("strong",[s._v("获取单个图书")]),n("br"),s._v("\n返回结果 "),n("code",[s._v('{"name":"红楼梦","price":"11","publish":"北京出版社"}')])])]),s._v(" "),n("p",[n("font",{attrs:{color:"#01a3a4",size:"4"}},[s._v("models.py")])],1),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" django"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("db "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" models\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Book")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    publish "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("32")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br")])]),n("p",[n("font",{attrs:{color:"#01a3a4",size:"4"}},[s._v("serializer.py")]),n("br"),s._v("\n通常会在app01下新建serializer.py文件! "),n("font",{attrs:{color:"gray"}},[s._v("(名自个儿取,通常叫这个名罢了)")]),n("br"),s._v(" "),n("font",{attrs:{color:"blue"}},[s._v("Django REST framework中的Serializer使用类来定义, 须继承自rest_framework.serializers.Serializer")])],1),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# from rest_framework.serializers import Serializer")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" rest_framework "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" serializers\n\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# serializers是一个py文件,Serializer是一个类!")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BookSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Serializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 通过序列化类控制需要序列化的字段")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 这里的CharField是drf提供的,跟Django models提供的CharField不是同一个东西!")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    Ps:选中CharField command+b 发现跳转到了fields.py文件!!这是因为做了一个代理.(了解)")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 在models.py中,Book表的price字段用的IntegerField类型")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    这里用CharField接收也是ok的,因为它可以从数据库中取到的数字映射成字符串!即用引号包起来.")]),s._v("\n    price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    publish "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br")])]),n("p",[n("font",{attrs:{color:"#01a3a4",size:"4"}},[s._v("urls.py")])],1),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" django"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("urls "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" re_path\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" django"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("contrib "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" admin\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" app01"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("views "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" BookView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" BookDetailView\n\nurlpatterns "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n    path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'admin/'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" admin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("site"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("urls"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'books/'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" BookView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("as_view"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- ★查询所有图书")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- Django2.x的re_path跟Django1.x的url一样!")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    Django1.x的有名分组 re_path(r'^books/(?P<pk>\\d+)', BookView.as_view()),")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- Django2.x使用 path转换器 达到同样的效果!")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    推荐使用转换器,因为有名分组的正则其一难写,其二其它地址也可能匹配成功.")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    path转换器默认有五种,str和int用的最多!! <转换器的类型:变量名>")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# eg: '/books/1'-> 将数字1传给变量pk,以关键字参数的形式 pk=1 传递给视图函数")]),s._v("\n    path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'books/<int:pk>'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" BookDetailView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("as_view"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- ★获取单个图书")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br")])]),n("p",[n("font",{attrs:{color:"#01a3a4",size:"4"}},[s._v("views.py")])],1),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" rest_framework"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("views "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" APIView\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" rest_framework"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("response "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Response\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("models "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Book\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("serializer "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" BookSerializer\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BookView")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("APIView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("get")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        book_list "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("objects"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("all")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# <QuerySet [<Book: Book object (1)>]>")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 需要改动的代码!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# l = []")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# for book in book_list:")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     l.append({'name': book.name, 'price': book.price})")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# return Response(l)")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 借助序列化类实现序列化!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    (序列化 -- 列表/字典转成json往外给; 反序列化 -- json转成列表/字典往数据库里存!)")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    实际上,完整的序列化的结果应该是json格式的字符串,但这里只是转换成了 列表/字典..")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    虽然不严谨,但我们也称该过程为序列化啦!不必纠结!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- BookSerializer类实例化触发的是它父类的父类BaseSerializer的__init__")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    参数instance: 需要序列化的数据")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#       1> 'queryset对象/列表嵌套字典/表中的多条记录'")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#       2>  或 '单个对象/单个字典/表中的单条记录'.")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    参数many: True--序列化多条,False--序列化单条. (不填默认为False)")]),s._v("\n        ser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" BookSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("book_list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" many"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 得到一个序列化对象")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" Response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 完成序列化")]),s._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BookDetailView")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("APIView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# def get(self, request, pk):")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("get")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        book "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("objects"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("all")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("pk"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'pk'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("first"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Book object (1)")]),s._v("\n        ser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" BookSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" Response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br")])]),n("h3",{attrs:{id:"常用字段类"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#常用字段类"}},[s._v("#")]),s._v(" 常用字段类")]),s._v(" "),n("blockquote",[n("p",[s._v("掌握这几个即可,其余的不晓得也没关系!"),n("br"),s._v(" "),n("font",{attrs:{color:"brown"}},[s._v("CharField 、 IntegerField 、DecimalField 、DateTimeField 、DateField")]),n("br"),s._v(" "),n("font",{attrs:{color:"brown"}},[s._v("ListField 、DictField")])],1)]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[s._v("BooleanField          Bool类型\nNullBooleanField      不为空的Bool"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("当数据库中存的"),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("bool")]),s._v("类型的字段设置了null"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),s._v("时"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("意味着可以不填\n                      往数据库里取数据进行序列化时"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("若为空"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("默认设置为"),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),s._v("\nCharField\nEmailField\nRegexField            与正则表达式有关\nSlugField\nURLField              存url地址的"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("用CharField不就行了吗?URLField的作用在于反序列化时的对url的验证\nUUIDField             uuid的格式"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("5ce0e9a5"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("5ffa"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("654b"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("cee0"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("1238041fb31a\nIPAddressField\nIntegerField\nFloatField\nDecimalField\nDateTimeField\nDateField\t\nTimeField\nDurationField\nChoiceField\nMultipleChoiceField\nFileField\nImageField\nListField\nDictField\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br")])]),n("h3",{attrs:{id:"常用字段类参数"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#常用字段类参数"}},[s._v("#")]),s._v(" 常用字段类参数")]),s._v(" "),n("blockquote",[n("p",[s._v("重点: "),n("strong",[s._v("read_only")]),s._v(" 、"),n("strong",[s._v("write_only")]),n("br"),s._v("\n了解: required 、default 、allow_null 、"),n("em",[s._v("validators")]),s._v(" 、error_messages"),n("br"),s._v("\n忽略: label 、help_text")]),s._v(" "),n("p",[s._v("CharField独有的 -- max_length 、min_length 、allow_blank 、trim_whitespace"),n("br"),s._v("\nIntegerField独有的 -- max_value 、min_value")])]),s._v(" "),n("h5",{attrs:{id:"通用的"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#通用的"}},[s._v("#")]),s._v(" 通用的")]),s._v(" "),n("table",[n("thead",[n("tr",[n("th",[s._v("参数名称")]),s._v(" "),n("th",[s._v("说明")])])]),s._v(" "),n("tbody",[n("tr",[n("td",[n("font",{attrs:{color:"brown"}},[s._v("read_only")])],1),s._v(" "),n("td",[n("font",{attrs:{color:"green"}},[s._v("表明该字段仅用于 "),n("strong",[s._v("序列化''输出''")]),s._v(" , 反序列化时忽略该字段, 默认False")])],1)]),s._v(" "),n("tr",[n("td",[n("font",{attrs:{color:"brown"}},[s._v("write_only")])],1),s._v(" "),n("td",[n("font",{attrs:{color:"green"}},[s._v("表明该字段仅用于 "),n("strong",[s._v("反序列化''输入''")]),s._v(" , 序列化时忽略该字段,  默认False")])],1)]),s._v(" "),n("tr",[n("td",[s._v("required")]),s._v(" "),n("td",[s._v("表明该字段在 "),n("strong",[s._v("反序列化时必须输入/填")]),s._v(" , 否则报错, 默认True")])]),s._v(" "),n("tr",[n("td",[s._v("default")]),s._v(" "),n("td",[s._v("反序列化时使用的默认值, "),n("font",{attrs:{color:"gray"}},[s._v("该字段也用不到,我们通常使用的是数据库里的默认值")])],1)]),s._v(" "),n("tr",[n("td",[s._v("allow_null")]),s._v(" "),n("td",[s._v("表明该字段是否允许 传入/前端往里写 None, 默认False "),n("font",{attrs:{color:"brown"}},[s._v("注意: 不传和传空是两码事!!")])],1)]),s._v(" "),n("tr",[n("td",[s._v("validators")]),s._v(" "),n("td",[s._v("该字段使用的验证器 "),n("font",{attrs:{color:"gray"}},[s._v("(写函数的列表,使用这些函数校验该字段)")])],1)]),s._v(" "),n("tr",[n("td",[s._v("error_messages")]),s._v(" "),n("td",[s._v("包含错误编号与错误信息的字典")])]),s._v(" "),n("tr",[n("td",[s._v("label")]),s._v(" "),n("td",[s._v("用于HTML展示API页面时，显示的字段名称")])]),s._v(" "),n("tr",[n("td",[s._v("help_text")]),s._v(" "),n("td",[s._v("用于HTML展示API页面时，显示的字段帮助提示信息")])])])]),s._v(" "),n("p",[n("font",{attrs:{color:"gray"}},[s._v("Ps: label、help_text在前后端分离的模式下几乎用不到,直接忽略.")])],1),s._v(" "),n("h5",{attrs:{id:"独有的"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#独有的"}},[s._v("#")]),s._v(" 独有的")]),s._v(" "),n("table",[n("thead",[n("tr",[n("th",[s._v("参数名称")]),s._v(" "),n("th",[s._v("作用")])])]),s._v(" "),n("tbody",[n("tr",[n("td",[s._v("max_length")]),s._v(" "),n("td",[s._v("最大长度")])]),s._v(" "),n("tr",[n("td",[s._v("min_length")]),s._v(" "),n("td",[s._v("最小长度")])]),s._v(" "),n("tr",[n("td",[s._v("allow_blank")]),s._v(" "),n("td",[s._v("是否允许为空")])]),s._v(" "),n("tr",[n("td",[s._v("trim_whitespace")]),s._v(" "),n("td",[s._v("是否截断空白字符")])]),s._v(" "),n("tr",[n("td",[s._v("max_value")]),s._v(" "),n("td",[s._v("最小值")])]),s._v(" "),n("tr",[n("td",[s._v("min_value")]),s._v(" "),n("td",[s._v("最大值")])])])]),s._v(" "),n("h3",{attrs:{id:"五个接口-序列-反序列"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#五个接口-序列-反序列"}},[s._v("#")]),s._v(" 五个接口(序列+反序列)")]),s._v(" "),n("blockquote",[n("p",[n("code",[s._v("books/")]),s._v(" 的get、post"),n("br"),s._v(" "),n("code",[s._v("books/<int:pk>")]),s._v(" 的get、put、delete")])]),s._v(" "),n("h5",{attrs:{id:"models-py"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#models-py"}},[s._v("#")]),s._v(" models.py")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" django"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("db "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" models\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Book")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    publish "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("32")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br")])]),n("h5",{attrs:{id:"urls-py"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#urls-py"}},[s._v("#")]),s._v(" urls.py")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" django"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("urls "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" path\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" django"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("contrib "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" admin\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" app01"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("views "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" BookView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" BookDetailView\n\n\nurlpatterns "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n    path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'admin/'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" admin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("site"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("urls"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'books/'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" BookView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("as_view"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 获取所有图书")]),s._v("\n    path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'books/<int:pk>'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" BookDetailView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("as_view"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 获取单个图书")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br")])]),n("h5",{attrs:{id:"serializer-py"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#serializer-py"}},[s._v("#")]),s._v(" serializer.py")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" rest_framework "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" serializers\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BookSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Serializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    publish "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("create")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- validated_data是前端提交过来校验通过的数据")]),s._v("\n        book "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("objects"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("create"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" book  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 一定要返回!若不返回,sre.data是拿不到的,你不晓得新增了谁.")]),s._v("\n                     "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- ★sre.data是以返回的这个对象做序列化的!!")]),s._v("\n      \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("update")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- instance是表中要修改的那条数据!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    validated_data是前端传过来的数据,有些字段可能没有,就用该条记录原来的字段值.")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'price'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("price"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("publish "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'publish'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("publish"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("save"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" instance  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 一定要返回!")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br")])]),n("h5",{attrs:{id:"views-py"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#views-py"}},[s._v("#")]),s._v(" views.py")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" rest_framework"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("views "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" APIView\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" rest_framework"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("response "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Response\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("models "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Book\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("serializer "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" BookSerializer\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BookView")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("APIView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- ◎ 获得所有图书")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("get")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 序列化")]),s._v("\n        qs "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("objects"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("all")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        ser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" BookSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("qs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" many"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 序列化的结果就是ser.data")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" Response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- ◎ 新增数据")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("post")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 反序列化")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- ★ 前端POST请求提交的数据,在body体中无论是什么格式(三种),都会放到request.data中")]),s._v("\n        ser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" BookSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_valid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 校验提交过来的数据是否合法,验证成功返回True,验证错误返回False.")]),s._v("\n            ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("save"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- ▲ 若是新增,使用save就新增啦!(修改也是)")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 1) request.data接收前端传过来的序列化好的数据")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 2) 后端将其反序列化的结果是ser,并保存到了数据库中")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3) ser.data将反序列化的结果进行了序列化")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" Response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'code'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'msg'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'新增成功'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'data'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" Response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'code'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("999")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'msg'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("errors"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BookDetailView")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("APIView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- ◎ 获得单本图书")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("get")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        book "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("objects"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("all")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("pk"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'pk'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("first"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 若没有找到 book的值为None,这里应该先判断有没有,有的话再序列化.. 不判断影响也不大.")]),s._v("\n        ser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" BookSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" Response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- ◎ 修改单本图书的信息")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        book "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("objects"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("all")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("pk"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'pk'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("first"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 拿到修改的数据request.data来修改book这个对象!")]),s._v("\n        ser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" BookSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_valid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 真正修改之前校验修改的数据是否合法!验证成功返回True,验证错误返回False.")]),s._v("\n            ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("save"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- ▲ 如果是修改,使用save就修改啦!(新增也是)")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" Response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'code'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'msg'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'修改成功'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'data'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" Response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'code'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("999")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'msg'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("errors"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- ◎ 删除单本图书")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("delete")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 返回的res指的是影响的行数")]),s._v("\n        res "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("objects"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("pk"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'pk'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("delete"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" res"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" Response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'code'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'msg'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'删除成功'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 数据不存在,也是一种变相的删除成功嘛.(´▽｀)")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" Response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'code'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("999")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'msg'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'数据不存在'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br"),n("span",{staticClass:"line-number"},[s._v("45")]),n("br"),n("span",{staticClass:"line-number"},[s._v("46")]),n("br"),n("span",{staticClass:"line-number"},[s._v("47")]),n("br"),n("span",{staticClass:"line-number"},[s._v("48")]),n("br"),n("span",{staticClass:"line-number"},[s._v("49")]),n("br"),n("span",{staticClass:"line-number"},[s._v("50")]),n("br"),n("span",{staticClass:"line-number"},[s._v("51")]),n("br"),n("span",{staticClass:"line-number"},[s._v("52")]),n("br"),n("span",{staticClass:"line-number"},[s._v("53")]),n("br"),n("span",{staticClass:"line-number"},[s._v("54")]),n("br"),n("span",{staticClass:"line-number"},[s._v("55")]),n("br"),n("span",{staticClass:"line-number"},[s._v("56")]),n("br"),n("span",{staticClass:"line-number"},[s._v("57")]),n("br"),n("span",{staticClass:"line-number"},[s._v("58")]),n("br")])]),n("h3",{attrs:{id:"save-的源码分析"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#save-的源码分析"}},[s._v("#")]),s._v(" save()的源码分析")]),s._v(" "),n("blockquote",[n("p",[n("font",{attrs:{color:"brown"}},[s._v("若继承的是Serializer类, 如果要保存和修改,一定要在 "),n("strong",[s._v("自定义的序列化器")]),s._v(" 里重写update和create!! ")]),n("br"),s._v("\nwhy? 从源码进行分析!")],1)]),s._v(" "),n("p",[n("font",{attrs:{color:"gray"}},[s._v("save()的查找过程 BookSerializer => Serializer => BaseSerializer -- save方法 ")]),n("br"),s._v(" "),n("font",{attrs:{color:"green"}},[n("strong",[s._v("save()的核心源码如下:")])]),n("br"),s._v("\n     意味着当我们在视图类的请求方法(post、put)里调用ser.save()时;"),n("br"),s._v("\n     会先判断自定义序列化类("),n("font",{attrs:{color:"gray"}},[s._v("这里是BookSerializer")]),s._v(")实例化时对instance参数进行初始化的值是否为None;"),n("br"),s._v("\n     若为None, 会调用BookSerializer里重写的create方法; 若不为None, 会调用BookSerializer里重写的update方法!")],1),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[s._v("validated_data "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("is")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("update"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 断言证明了 重写的update方法必须返回一个对象")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("assert")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("is")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'`update()` did not return an object instance.'")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("create"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 断言证明了 重写的create方法必须返回一个对象")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("assert")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("is")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'`create()` did not return an object instance.'")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("instance\n\n\nQ"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" 若在BookSerializer中不重写update和create方法呢?\nA"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" 根据查找规则"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("会在BaseSerializer类里找到这两个方法!!源码如下"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n   这也就证明了BookSerializer中为啥一定要重写这两个方法!!\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("create")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("raise")]),s._v(" NotImplementedError"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'`create()` must be implemented.'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("   \n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("update")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("raise")]),s._v(" NotImplementedError"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'`update()` must be implemented.'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nPs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("这里"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("raise")]),s._v("主动抛出异常"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("涉及到接口、鸭子类型的概念!!\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br")])]),n("hr"),s._v(" "),n("h2",{attrs:{id:"进阶"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#进阶"}},[s._v("#")]),s._v(" 进阶")]),s._v(" "),n("h3",{attrs:{id:"反序列化的验证"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#反序列化的验证"}},[s._v("#")]),s._v(" 反序列化的验证")]),s._v(" "),n("blockquote",[n("p",[s._v("操作serializer.py!! -- "),n("strong",[s._v("给字段设置参数")]),s._v(", "),n("font",{attrs:{color:"brown"}},[s._v("会在post、put反序列化时进行验证!!!!")])],1)]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("⁎⁍̴̛ᴗ⁍̴̛⁎"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" ★★★★★★ 只有我自己看得懂的理解"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\nname1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" read_only"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" source"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),s._v("\nname  "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" write_only"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),s._v("\n无论序列化还是反序列化"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("先进行自定义序列化类初始化得到序列化对象ser\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data完成序列化时是包含name1字段"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("不包含name字段的!\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 反序列化的过程"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("会进行校验后"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("执行save方法"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("调用重写的两个方法之一"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("观察validated_data的值可以判断通过校验的字段\n   也就是说通过校验的字段是包含name字段"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("不包含name1字段的!!\n   反序列化保存数据库成功后"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("会再次ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data序列化返回前端信息"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n从后端的处理逻辑思考问题"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("前端不过是提交给后端数据或者拿到后端返回的值"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br")])]),n("h5",{attrs:{id:"独有的参数"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#独有的参数"}},[s._v("#")]),s._v(" 独有的参数")]),s._v(" "),n("p",[n("img",{attrs:{src:a(764),alt:""}})]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" rest_framework "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" serializers\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("models "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Book\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BookSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Serializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("min_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("min_value"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_value"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    publish "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("create")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- validated_data是校验通过的数据,在这里name字段read_only,所以是没有的!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# {'price': 5, 'publish': '上海出版社'}")]),s._v("\n        book "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("objects"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("create"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" book\n      \n     "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("update")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'price'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("price"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("publish "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'publish'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("publish"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("save"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" instance\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br")])]),n("p",[s._v("为了保证校验不合格时返回的错误信息是中文,需要在settings.py中进行国际化的配置!! 记得注册rest_framework."),n("br"),s._v(" "),n("font",{attrs:{color:"blue"}},[s._v("若国际化不是很成功,可以添加给字段添加 "),n("strong",[s._v("error_messages")]),s._v(" 属性!!")]),n("br"),s._v(" "),n("code",[s._v("name = serializers.CharField(min_length=3, max_length=8, error_messages={'min_length': '不够.'})")])],1),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n-- 国际化!\n"""')]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# LANGUAGE_CODE = 'en-us'")]),s._v("\nLANGUAGE_CODE "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'zh-hans'")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 东八区的时间")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    上海的S要大写,小写的在windows上没问题,在Linux上会报错!")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# TIME_ZONE = 'UTC'")]),s._v("\nTIME_ZONE "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Asia/Shanghai'")]),s._v("\nUSE_I18N "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),s._v("\nUSE_L10N "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# USE_TZ = True")]),s._v("\nUSE_TZ "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 使用非UTC的时间")]),s._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n若不国际化,前端得到的返回结果是\n{\n    "code": 999,\n    "msg": {\n        "name": [\n            "Ensure this field has at least 3 characters."\n        ],\n        "price": [\n            "Ensure this value is greater than or equal to 3."\n        ]\n    }\n}\n"""')]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br")])]),n("h5",{attrs:{id:"read-only参数"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#read-only参数"}},[s._v("#")]),s._v(" read_only参数")]),s._v(" "),n("blockquote",[n("p",[n("font",{attrs:{color:"brown"}},[s._v("从后端角度看,仅用于序列化, 反序列化时忽略该字段!! ")]),n("br"),s._v(" "),n("strong",[s._v("也就是说get请求,后端查询时是有该字段的; post增加/put修改请求, 后端操作的数据中 没有/忽略 该字段的!!")])],1)]),s._v(" "),n("p",[n("font",{attrs:{color:"gray"}},[s._v("仅用于序列化,往外走有这个字段!! 往里进的时候,反序列化的数据中是没有该字段的!!")])],1),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" rest_framework "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" serializers\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("models "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Book\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BookSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Serializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("min_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" read_only"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("min_value"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_value"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    publish "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("create")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- validated_data是校验通过的数据,在这里name字段read_only,所以是没有的!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# {'price': 5, 'publish': '上海出版社'}")]),s._v("\n        book "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("objects"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("create"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" book\n      \n     "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("update")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'price'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("price"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("publish "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'publish'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("publish"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("save"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" instance\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br")])]),n("p",[n("img",{attrs:{src:a(765),alt:""}})]),s._v(" "),n("p",[n("font",{attrs:{color:"green"}},[n("strong",[s._v("注意!")]),s._v(" 因为项目里用的sqlite文件数据库,没有那么高的限制, 所以存进去了; 若使用的是mysql数据库,会直接报错,存不进去的, 因为在model.py里给Book表设置name字段时,并没有给该字段添加null=True的属性,Django默认字段的null=False,即该字段不能为空!! ")])],1),s._v(" "),n("h5",{attrs:{id:"write-only参数"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#write-only参数"}},[s._v("#")]),s._v(" write_only参数")]),s._v(" "),n("blockquote",[n("p",[n("font",{attrs:{color:"brown"}},[s._v("从后端角度看,仅用于反序列化, 序列化时忽略该字段!! ")]),n("br"),s._v(" "),n("strong",[s._v("也就是post增加/put修改请求, 后端操作的数据中是有该字段的; get请求,后端查询时是 没有/忽略 该字段的;")])],1)]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" rest_framework "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" serializers\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("models "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Book\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BookSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Serializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 若Book表中没有name1这个字段,可以指定个参数source!")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    source='name' 意味着将name1映射成models中Book表的name!")]),s._v("\n    name1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("min_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" read_only"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" source"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("min_value"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_value"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    publish "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 该字段只用于反序列化!序列化时忽略该字段!")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    这里不能写成name2,然后再指定个source='name'")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    因为重写的create方法里**validated_data会将前端传过来的序列化数据打散,要保证book表中有对应字段!")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("write_only"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("create")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        book "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("objects"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("create"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" book\n      \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("update")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'price'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("price"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("publish "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'publish'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("publish"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("save"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" instance\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br")])]),n("p",[n("font",{attrs:{color:"gray"}},[s._v("Ps: 说实话,挺奇怪的.. 直接 name = serializers.CharField(min_length=3, max_length=8) 不好吗? ")]),n("br"),s._v(" "),n("font",{attrs:{color:"gray"}},[s._v("read_only和write_only的应用场景不是很明确!")])],1),s._v(" "),n("p",[n("em",[s._v("先post请求增加一条数据")])]),s._v(" "),n("p",[n("img",{attrs:{src:a(766),alt:""}})]),s._v(" "),n("p",[n("em",[s._v("再get请求查找所有数据")])]),s._v(" "),n("p",[n("img",{attrs:{src:a(767),alt:""}})]),s._v(" "),n("hr"),s._v(" "),n("h2",{attrs:{id:"高级"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#高级"}},[s._v("#")]),s._v(" 高级")]),s._v(" "),n("h3",{attrs:{id:"数据准备"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#数据准备"}},[s._v("#")]),s._v(" 数据准备")]),s._v(" "),n("blockquote",[n("p",[n("em",[n("strong",[s._v("实验准备:")])]),s._v(" 改变下model, "),n("font",{attrs:{color:"blue"}},[s._v("添加个外键关联表")]),s._v(" - Publish出版社表! 并添加数据便于实验!")],1)]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" django"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("db "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" models\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Book")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 默认关联Publish的主键")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 1.x上默认on_delete=models.CASCADE级联删除 2.x上需要自己加")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    级联删除 删了某个出版社,该出版社下的书全没了.不合理.暂且这样吧.")]),s._v("\n    publish "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ForeignKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("to"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Publish'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("on_delete"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CASCADE"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Publish")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    addr "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br")])]),n("h3",{attrs:{id:"序列化时字段格式"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#序列化时字段格式"}},[s._v("#")]),s._v(" 序列化时字段格式")]),s._v(" "),n("blockquote",[n("p",[n("font",{attrs:{color:"blue"}},[s._v("我们可以指定 "),n("strong",[s._v("序列化时")]),s._v(" , 某个字段展示在前端的格式.")]),n("br"),s._v(" "),n("font",{attrs:{color:"brown"}},[s._v("注意: 三种方式的前提都是只用于序列化,相当于加了参数 read_only=True")])],1)]),s._v(" "),n("h5",{attrs:{id:"未指定"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#未指定"}},[s._v("#")]),s._v(" 未指定")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" rest_framework "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" serializers\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BookSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Serializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("min_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("min_value"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_value"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    publish "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br")])]),n("p",[n("img",{attrs:{src:a(768),alt:""}})]),s._v(" "),n("p",[s._v("需求:我们需要在前端显示出版社的详情")]),s._v(" "),n("h5",{attrs:{id:"方式一-不常用"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#方式一-不常用"}},[s._v("#")]),s._v(" 方式一(不常用)")]),s._v(" "),n("blockquote",[n("p",[n("strong",[s._v("在序列化类中写")])])]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" rest_framework "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" serializers\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BookSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Serializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("min_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("min_value"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_value"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# publish = serializers.CharField()")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#   使用SerializerMethodField !只适用于做序列化!相对于加了参数read_only=True")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#   只用于序列化,这个字段名就没啥好讲究的了.")]),s._v("\n    publish_1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("SerializerMethodField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 必须配套个方法,方法名固定写法 get_字段名")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    参数obj是要序列化的对象,此处是book对象!")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("get_publish_1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" obj"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 返回出版社的名字")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    book对象.publish外键=>跨到了Publish表,再.name取到对应出版社的名字")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# return obj.publish.name")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 返回出版社的详情")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" obj"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("publish"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'addr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" obj"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("publish"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("addr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br")])]),n("p",[n("img",{attrs:{src:a(769),alt:""}})]),s._v(" "),n("h5",{attrs:{id:"方式二-最常用"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#方式二-最常用"}},[s._v("#")]),s._v(" 方式二(最常用)")]),s._v(" "),n("blockquote",[n("p",[n("strong",[s._v("在表对应的模型类中写")]),s._v(" , 方法返回什么, 这个字段就是什么!!")])]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n-- models.py\n"""')]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" django"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("db "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" models\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Book")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    publish "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ForeignKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("to"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Publish'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" on_delete"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CASCADE"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# @property  # -- 是否包装成数据属性都行.可加可不加.")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("publish_detail")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("publish"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"addr"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("publish"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("addr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Publish")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    addr "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("64")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    \n    \n    \n"),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('"""\n-- serializer.py\n"""')]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" rest_framework "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" serializers\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BookSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Serializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("min_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("min_value"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_value"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# publish = serializers.CharField()")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# publish_detail = serializers.CharField()")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- ★★★ 特别注意!应该使用字段类型DictField")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    若models里模型类的publish_detail方法返回的是列表,那么应该使用ListField!!")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 只用于做序列化,相对于加了参数read_only=True")]),s._v("\n    publish_detail "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("DictField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 使用CharField,publish_detail的值是字符串,字符串包裹的是一个字典.")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# [")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     {")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#         "name": "红楼梦",')]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v('#         "price": 11,')]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#         \"publish_detail\": \"{'name': '南京出版社', 'addr': '南京'}\"")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#     }")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ]")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br")])]),n("p",[n("img",{attrs:{src:a(770),alt:""}})]),s._v(" "),n("h5",{attrs:{id:"方式三-了解"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#方式三-了解"}},[s._v("#")]),s._v(" 方式三(了解)")]),s._v(" "),n("blockquote",[n("p",[s._v("方式三没法显示出版社详情.")])]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" rest_framework "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" serializers\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BookSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Serializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("min_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("min_value"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_value"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 只用于做序列化,相对于加了参数read_only=True")]),s._v("\n    publish_name1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("source"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'publish.name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br")])]),n("p",[n("img",{attrs:{src:a(771),alt:""}})]),s._v(" "),n("h3",{attrs:{id:"book表的接口实验"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#book表的接口实验"}},[s._v("#")]),s._v(" Book表的接口实验")]),s._v(" "),n("p",[s._v("五个接口的代码不变,只需改变下BookSerializer类的一些代码!")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" rest_framework "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" serializers\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("models "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Publish\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BookSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Serializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("min_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("min_value"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_value"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    publish_detail "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("DictField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("read_only"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 使用的是方式二")]),s._v("\n    publish_id "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("write_only"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("create")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# print(validated_data)")]),s._v("\n        book "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("objects"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("create"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" book\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("update")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# print(validated_data)")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'price'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("price"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("publish_id "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'publish_id'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("publish_id"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("save"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" instance\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br")])]),n("p",[s._v("实验过程如下:")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" GET http"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("//")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v(".0")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v(".1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8000")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("books"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("\n   结果"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n       "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"红楼梦"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"price"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"publish_detail"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"南京出版社"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"addr"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"南京"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n      \n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" GET http"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("//")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v(".0")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v(".1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8000")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("books"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n   结果"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n       "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"红楼梦"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"price"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"publish_detail"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"南京出版社"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"addr"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"南京"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n      \n   GET http"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("//")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v(".0")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v(".1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8000")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("books"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("\n   结果"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n       "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('""')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"price"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("null"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"publish_id"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('""')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n   分析"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n       该路由会调用BookDetailView类的get方法"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("没有查询到"),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("id")]),s._v("为"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("的图书"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("实例化序列器类时instance的值为"),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n       阴差阳错的调用的是BookSerializer类里重写的 update方法!\n\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" POST http"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("//")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v(".0")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v(".1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8000")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("books"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("   \n   传递给后端的Json数据"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"西游记"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"price"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"publish_id"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n   Ps"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" 得是publish_id"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("不然报错Cannot assign "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("\"'1'\"")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Book.publish"')]),s._v(" must be a "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Publish"')]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n       因为models模型里使用了ForeignKey"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n       若使用的是ModelSerializer类"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("写publish就行!!\n   结果"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n       "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"code"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"msg"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"新增成功"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"data"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"西游记"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"price"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"publish_detail"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"南京出版社"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"addr"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"南京"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" PUT http"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("//")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v(".0")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v(".1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8000")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("books"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("  \n   传递给后端的Json数据"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n       "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"西游记"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"price"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"publish_id"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n   结果"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n       "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"code"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"msg"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"修改成功"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"data"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n             "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"西游记"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n             "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"price"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n             "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"publish_detail"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n                 "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"name"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"南京出版社"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                 "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"addr"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v('"南京"')]),s._v("\n              "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n          "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n   补充说明"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n       若要修改的图书"),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("id")]),s._v("查询结果为"),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("和前面`GET http"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("//")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("127.0")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v(".0")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v(".1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8000")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("books"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("`同理"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n       阴差阳错的调用的是BookSerializer类里重写的update方法!相当于新增了一条数据"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br")])]),n("h3",{attrs:{id:"其它"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#其它"}},[s._v("#")]),s._v(" 其它")]),s._v(" "),n("p",[s._v("像什么序列化类的局部钩子(通过validate_字段名进行字段的验证)、全局钩子等. 在 ModelSerializer类中讲解."),n("br"),s._v("\n因为序列化类ModelSerializer继承了序列化类Serializer!!  Serializer有的ModelSerializer都有!!")]),s._v(" "),n("hr")])}),[],!1,null,null,null);t.default=e.exports},764:function(s,t,a){s.exports=a.p+"assets/img/20.4825952d.jpeg"},765:function(s,t,a){s.exports=a.p+"assets/img/4.3604b53f.jpeg"},766:function(s,t,a){s.exports=a.p+"assets/img/8.6cc5fc4a.jpeg"},767:function(s,t,a){s.exports=a.p+"assets/img/16.3ba9699b.png"},768:function(s,t,a){s.exports=a.p+"assets/img/14.00da9865.png"},769:function(s,t,a){s.exports=a.p+"assets/img/12.9bea789c.jpeg"},770:function(s,t,a){s.exports=a.p+"assets/img/15.165692c6.jpeg"},771:function(s,t,a){s.exports=a.p+"assets/img/13.c9bc8e99.png"}}]);