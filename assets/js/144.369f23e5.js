(window.webpackJsonp=window.webpackJsonp||[]).push([[144],{1282:function(s,t,a){"use strict";a.r(t);var n=a(0),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,n=s._self._c||t;return n("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[n("p",[n("font",{attrs:{color:"red"}},[s._v("!!本篇将阐述序列化类ModelSerializer的使用!!")]),n("br"),s._v("\nBook表和Publish表中都有name字段,现有一个自定义的序列化类BookSerializer,里面指定了需要序列化的字段name."),n("br"),s._v("\n我既可以用BookSerializer序列化Book表,也可以用它来序列化Publish表!!"),n("br"),s._v(" "),n("font",{attrs:{color:"blue"}},[s._v("So,我想说的是 序列化类Serializer跟models里的表模型没有必然的联系!")]),n("br"),s._v(" "),n("font",{attrs:{color:"green"}},[n("em",[s._v("下面我们要学习的序列化类ModelSerializer是跟表模型有对应关系的!!")]),s._v("  o(^▽^)o .")])],1),s._v(" "),n("h2",{attrs:{id:"modelserializer"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#modelserializer"}},[s._v("#")]),s._v(" ModelSerializer"),n("code",[s._v("*****")])]),s._v(" "),n("blockquote",[n("p",[s._v("序列化类ModelSerializer, 项目中基本上用的都是它! ModelSerializer继承Serializer.")])]),s._v(" "),n("h3",{attrs:{id:"准备工作"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#准备工作"}},[s._v("#")]),s._v(" 准备工作")]),s._v(" "),n("p",[s._v("路由配置")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" django"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("urls "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" path\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" django"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("contrib "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" admin\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" app01 "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" views\n\nurlpatterns "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n    path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'admin/'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" admin"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("site"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("urls"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'books/'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" views"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("BookView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("as_view"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("                     "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 获取所有图书")]),s._v("\n    path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'books/<int:pk>'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" views"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("BookDetailView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("as_view"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("       "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 获取单个图书")]),s._v("\n    path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'publish/'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" views"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("PublishView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("as_view"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("                "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 获取所有出版社")]),s._v("\n    path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'publish/<int:pk>'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" views"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("PublishDetailView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("as_view"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 获取单个出版社")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br")])]),n("p",[s._v("为出版社的Publish表写5个接口("),n("font",{attrs:{color:"gray"}},[s._v("与书Book表的五个接口相比,没有什么区别,就改了改类名")]),s._v(")")],1),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" rest_framework"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("views "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" APIView\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" rest_framework"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("response "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Response\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("models "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Publish\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("serializer "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" BookSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" PublishModelSerializer\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BookView")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("APIView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("pass")]),s._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BookDetailView")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("APIView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("pass")]),s._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PublishView")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("APIView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("get")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        qs "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Publish"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("objects"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("all")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        ser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" PublishModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("qs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" many"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" Response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("post")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        ser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" PublishModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_valid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("save"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" Response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'code'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'msg'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'新增成功'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'data'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" Response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'code'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("999")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'msg'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("errors"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PublishDetailView")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("APIView"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("get")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        book "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Publish"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("objects"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("all")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("pk"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'pk'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("first"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        ser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" PublishModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" Response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("put")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        book "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Publish"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("objects"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("all")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("pk"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'pk'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("first"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        ser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" PublishModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_valid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("save"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" Response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'code'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'msg'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'修改成功'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'data'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" Response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'code'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("999")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'msg'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("errors"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("delete")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("args"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        res "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Publish"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("objects"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("pk"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("kwargs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'pk'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("delete"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" res"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" Response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'code'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'msg'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'删除成功'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" Response"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'code'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("999")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'msg'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'数据不存在'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br"),n("span",{staticClass:"line-number"},[s._v("45")]),n("br"),n("span",{staticClass:"line-number"},[s._v("46")]),n("br"),n("span",{staticClass:"line-number"},[s._v("47")]),n("br"),n("span",{staticClass:"line-number"},[s._v("48")]),n("br")])]),n("h3",{attrs:{id:"需求实现"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#需求实现"}},[s._v("#")]),s._v(" 需求实现")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PublishModelSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 在内部类Meta中指定跟表的对应关系.")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Meta")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        model "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Publish  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 跟哪个表有关系")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# fields = '__all__'  # -- 表中的所有字段都做序列化,★注意是不包括表模型里的方法的!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    ★ 这些字段的字段类是通过表模型映射过来的!!并且把表模型里那些属性像什么max_length=64,null=True也映射过来啦!!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#      也就意味着反序列化验证时,该字段不能超过64位,且可以为空.")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 指定字段或者方法做序列化/反序列化")]),s._v("\n        fields "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'addr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 在该序列化类里不用再重写create和update方法!!!")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    因为使用Serializer类时,是不知道要存哪个表,但使用ModelSerializer时,有表的对应关系啦!")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br")])]),n("h5",{attrs:{id:"指定字段"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#指定字段"}},[s._v("#")]),s._v(" 指定字段")]),s._v(" "),n("blockquote",[n("p",[n("em",[n("strong",[s._v("指定某个字段序列化的格式!!")])])]),s._v(" "),n("p",[n("strong",[s._v("需求:")]),s._v(" 序列化时,在出版社的名字后加上 _vip"),n("br"),s._v("\n解决方案: "),n("em",[s._v("重写字段")]),s._v(", 具体来说,就是指序列化时指定字段格式的三种方式!!我们掌握前两种即可.")])]),s._v(" "),n("p",[n("font",{attrs:{color:"blue"}},[n("strong",[s._v("注意,")]),s._v(" 在ModelSerializer中会优先使用重写的字段序列化")])],1),s._v(" "),n("p",[s._v("方式一: 使用SerializerMethodField")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PublishModelSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Meta")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        model "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Publish\n        fields "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'addr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("SerializerMethodField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("get_name")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" obj"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" obj"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'_vip'")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br")])]),n("p",[s._v("方式二: 在表模型中定义一个name_suffix的方法,并写入内部类的fields列表中."),n("br"),s._v(" "),n("font",{attrs:{color:"gray"}},[s._v("注意思考下,使用该方式时,要结合这read_only使用!!")])],1),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PublishModelSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Meta")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        model "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Publish\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# fields = '__all__'  # -- 表中的所有字段都做序列化,★注意是不包括表模型里的方法的!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 指定字段或者方法做 序列化/反序列化")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    ★ 这些字段的字段类是通过表模型映射过来的!!并且把表模型里那些属性像什么max_length=64,null=True也映射过来啦!!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#      也就意味着反序列化验证时,该字段不能超过64位,且可以为空.")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    name_suffix方法的返回值会同时映射到'name_suffix'和'name'上面")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    返回值是什么,它俩序列化后的值就是什么")]),s._v("\n        fields "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'addr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name_suffix'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 方式二: ")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[s._v('""" 表模型中的代码如下\n    class Publish(models.Model):\n        name = models.CharField(max_length=64)\n        addr = models.CharField(max_length=64)\n        def name_suffix(self):\n            return self.name + \'_vip\'\n    """')]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#  我们发现序列化展示的结果,'name_suffix'和'name'都展示了,且值都是一样的!只需要一个即可.")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    ▲ 需求:序列化时使用name_suffix,反序列化时使用mame")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    该行代码可以不写,因为默认表模型里方法在反序列化时不需要有对应的值！")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    name_suffix = serializers.CharField(read_only=True)")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("write_only"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br")])]),n("h5",{attrs:{id:"添加字段限制"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#添加字段限制"}},[s._v("#")]),s._v(" 添加字段限制")]),s._v(" "),n("blockquote",[n("p",[n("strong",[s._v("需求:")]),s._v(" 反序列化时,限制addr,最大长度为8,最小长度为3"),n("br"),s._v("\n解决方案: 1) 重写该字段     2) 借助extra_kwargs")])]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PublishModelSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Meta")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        model "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Publish\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# fields = '__all__'")]),s._v("\n        fields "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'addr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 给字段映射的字段类添加一些属性/为字段类设置字段参数!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    比如name字段映射的字段类是CharField")]),s._v("\n        extra_kwargs "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'addr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'max_length'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'min_length'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 'name': {'write_only': True}")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("    \n  \n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 方式一:重写addr")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# name = serializers.CharField(max_length=8, min_length=3)")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 方式二:在内部类的extra_kwargs中为addr字段设置参数")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br")])]),n("h5",{attrs:{id:"局部钩子"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#局部钩子"}},[s._v("#")]),s._v(" 局部钩子")]),s._v(" "),n("blockquote",[n("p",[n("strong",[s._v("需求:")]),s._v(" 反序列化时,addr字段的值最大长度为8,最小长度为3且不能以'sb'开头!"),n("br"),s._v("\n解决方案: 局部钩子 -- 给某个字段再增加一些校验! 固定用法"),n("code",[s._v("def validate_校验的字段():pass")])])]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PublishModelSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Meta")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        model "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Publish\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# fields = '__all__'")]),s._v("\n        fields "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'addr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        extra_kwargs "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'addr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'max_length'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'min_length'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 参数item,此形参名随便起,对应前端传过来的addr的值")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("validate_addr")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("startswith"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sb'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 抛出异常,但需要清楚的知道APIview里捕获了全局异常并进行了处理!!!")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("raise")]),s._v(" ValidationError"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'不能以sb开头!'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" item  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- ★★★一定要记得return item!!!")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br")])]),n("h5",{attrs:{id:"全局钩子"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#全局钩子"}},[s._v("#")]),s._v(" 全局钩子")]),s._v(" "),n("blockquote",[n("p",[n("strong",[s._v("需求:")]),s._v(" 反序列化时,限制出版社的名字不能等于出版社的地址."),n("br"),s._v("\n解决方案: 全局钩子!方法名就叫做validate.")])]),s._v(" "),n("p",[n("font",{attrs:{color:"brown"}},[n("strong",[s._v("注意一点:")])]),n("br"),s._v("\n    局部钩子在全局钩子之前执行,若局部钩子validate_addr方法return 'lqz'"),n("br"),s._v(" "),n("font",{attrs:{color:"blue"}},[s._v("那么")]),s._v("在全局钩子validate里attrs.get('addr')拿到的addr就是'lqz',就不是前端提交过来的值啦!!")],1),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PublishModelSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Meta")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        model "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Publish\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# fields = '__all__'")]),s._v("\n        fields "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'addr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        extra_kwargs "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("validate")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" attrs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" attrs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        addr "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" attrs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'addr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" addr"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("raise")]),s._v(" ValidationError"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'不能以sb开头!'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" attrs  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- ★★★一定要记得return attr!!!")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br")])]),n("h5",{attrs:{id:"meta中其它变量"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#meta中其它变量"}},[s._v("#")]),s._v(" Meta中其它变量")]),s._v(" "),n("blockquote",[n("p",[s._v("exclude 、depth")])]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PublishModelSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 在内部类Meta中指定跟表的对应关系.")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Meta")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        model "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Publish  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 跟哪个表有关系")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# fields = '__all__'  # -- 表中的所有字段都做序列化,★注意是不包括表模型里的方法的!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 指定字段或者方法做序列化/反序列化")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    ★ 这些字段的字段类是通过表模型映射过来的!!并且把表模型里那些属性像什么max_length=64,null=True也映射过来啦!!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#      也就意味着反序列化验证时,该字段不能超过64位,且可以为空.")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    name_suffix方法的返回值会同时映射到'name_suffix'和'name'上面")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    返回值是什么,它俩序列化后的值就是什么")]),s._v("\n        fields "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'addr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name_suffix'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 给字段映射的字段类添加一些属性/为字段类设置字段参数!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    比如name字段映射的字段类是CharField")]),s._v("\n        extra_kwargs "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'addr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'max_length'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'min_length'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 'name': {'write_only': True}")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ps:简单介绍下,字段参数validators!使用指定的函数来校验字段.")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    将name字段抛到函数里,函数里校验不通过也会抛ValidationError")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    ★ 跟局部钩子的区别在于,局部钩子只能用都在某个字段上,validators里的函数1、函数2可以用到多个字段上.")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 'name': {'validators': [函数1,函数2]}")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 内部类Meta中其它不重要的变量(用的很少)")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- exclude 排除, exclude和fields只能有一个!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    几乎不用!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# exclude = ['name']  # -- 排除name字段,其它字段都序列化")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- depth 会自动将外键字段关联表的记录序列化出来.该记录中若还有外键,会继续序列化,数字代表几层.")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    不建议用,因为会将外键字段关联的表对应的记录的字段全部序列化展示出来!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# depth = 1")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br")])]),n("h3",{attrs:{id:"改写下book"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#改写下book"}},[s._v("#")]),s._v(" 改写下Book")]),s._v(" "),n("blockquote",[n("p",[s._v("注意哦,Book模型表是写了该语句的 "),n("code",[s._v("publish = models.ForeignKey(to='Publish', on_delete=models.CASCADE)")])])]),s._v(" "),n("h5",{attrs:{id:"改写前"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#改写前"}},[s._v("#")]),s._v(" 改写前")]),s._v(" "),n("p",[n("img",{attrs:{src:a(772),alt:""}})]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BookSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Serializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("min_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_length"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("IntegerField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("min_value"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" max_value"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    publish_detail "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("DictField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("read_only"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    publish_id "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("write_only"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("create")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        book "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("objects"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("create"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" book\n\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("update")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'price'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("price"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("publish_id "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validated_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'publish_id'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("publish_id"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        instance"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("save"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" instance\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br")])]),n("h5",{attrs:{id:"改写后"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#改写后"}},[s._v("#")]),s._v(" 改写后")]),s._v(" "),n("p",[s._v("记得在views.py里将BookSerializer改为BookModelSerializer.")]),s._v(" "),n("p",[n("img",{attrs:{src:a(773),alt:""}})]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("BookModelSerializer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ModelSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Meta")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        model "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Book\n        fields "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'price'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'publish'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'publish_detail'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 给字段映射的字段类添加一些属性/为字段类设置字段参数!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    比如name字段映射的字段类是CharField")]),s._v("\n        extra_kwargs "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'addr'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'max_length'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'min_length'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'publish'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'write_only'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br")])]),n("hr"),s._v(" "),n("h2",{attrs:{id:"总结"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[s._v("#")]),s._v(" 总结!!")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 序列化类之Serializer\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 跟表模型没有必然联系"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("必须重写create和update方法\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 写出要序列化的字段 \n   注意"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("Serializer类中序列化字段的类型尽量跟表模型当中字段的类型相对应\n     eg"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" \n       "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- Book表的price字段用的IntegerField类型")]),s._v("\n       "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 这里用CharField也是ok的,因为它可以从数据库中取到的数字用引号包起来弄成字符串.")]),s._v("\n       "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 但尽量还是用 serializers.IntegerField!!")]),s._v("\n       price "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n   注意"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("若字段序列化后的值是字典或者列表"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("用CharField的话"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("前端接收到的是用引号包裹的字典或者列表"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("不是json"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n       这种情况常出现于 “指定字段” 的方式二里!! 解决方案"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("用DictField、ListField即可!\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 字段类的source参数"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("用的很少"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   这样的话"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("序列化的字段名就不需要等于表模型当中的字段名"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("会根据source参数的值映射过去!\n   eg"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" price_0 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" serializers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("CharField"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("source"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'price'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 注意,price_0改成price会报错.只有不为price就行!")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 字段类\n   CharField\n   IntegerField\n   DateTimeField\n   DateField\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 字段类参数\n   "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 通用\n     read_only"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" \n         该字段只用于序列化"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("反序列化往里走的时候不需要该字段"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("即便传了"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("也不会处理"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n         最直观的体现就是validated_data里没有!因为不识别该字段"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n     write_only"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n         该字段只用于反序列化"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("序列化往外走的时候不需要该字段"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("即便传了"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("也不会处理"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n     PS"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("往里走指前端到后端"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("后端保存数据库"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("往外走指后端到前端!\n     Ps"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("使用这两个参数可以实现在一个序列化类里实现序列化和反序列化的操作!!\n     注意"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("一个字段类不能同时用这两个参数!既只读又只写?\n   "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 独有\n     记不住也没关系"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("还可以用局部钩子来实现"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("不影响俺们做开发\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 局部钩子和全局钩子\n   字段类可以设置一些自己的验证规则"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("但除此之外还想多加一点验证"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n   反序列化时"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("验证前端提交过来的数据!\n   验证顺序"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" 自己规则 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 局部钩子 "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 全局钩子\n\t "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 局部钩子 \n     "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- item拿到的是相对应字段的那一个数据")]),s._v("\n     "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" validate_字段名"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 格外的一些验证,写正则也可以")]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 校验通过,直接return item;校验失败,抛ValidationError的异常!")]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("pass")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 全局钩子\n     "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- attr拿到的是前端传过来的所有的数据")]),s._v("\n     "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("validate")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("attrs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 校验通过,直接return attrs;校验失败,抛ValidationError的异常!")]),s._v("\n         "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("pass")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 序列化类之ModelSerializer\n   ModelSerializer继承自Serializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("是Serializer的子类"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("Serializer有的"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("它都有\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 跟表模型有必然联系"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("不需要重写create和update方法\n   "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ModelSerializer帮我们写了"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      create源码"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("会动态的获取模型表进行create"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("有需要的话"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("还可顺带存第三张表\n      update源码"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("通过反射的方式实现的"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("跟一个个取出来的方式效果一样"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n   注意"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("不是说一定不需要重写"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("有些情况还是需要的"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n       比如说"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("新增一个用户"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("与用户相关的有user表和userdetail表"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("前端往后端提交数据"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("提两次?一次基本信息一次详细信息?\n       No"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("都是一个表单一次性提交上来的"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("这种情况就需要重写create、update"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("把值取出来自己处理!\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 需要写一个内部类Meta"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("Meta里再写一些类属性\n   "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Meta")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n       model "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" 表模型\n       "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- fields需要序列化以及反序列化的字段")]),s._v("\n       "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    ★ 这些字段的字段类是通过表模型映射过来的!!并且把表模型里那些属性像什么max_length=64,null=True也映射过来啦!!")]),s._v("\n       "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#      也就意味着反序列化验证时,该字段不能超过64位,且可以为空.")]),s._v("\n       "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# fields = '__all__'  ")]),s._v("\n       fields "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'字段'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'方法'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 这种方式既能拿表模型里的字段,也能拿表模型里的方法 ")]),s._v("\n       extra_kwargs "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'字段'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 可以重写要序列化的字段\n   一般来说"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("能通过extra_kwargs来达到目的的话"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("就不需要重写该字段啦\n"),n("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 指定某个字段序列化的格式 "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("有三种"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("记住前两种即可"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 在表模型中写方法"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("可以包装成数据属性"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n   "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 在序列化类中使用SerializerMethodField\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br"),n("span",{staticClass:"line-number"},[s._v("45")]),n("br"),n("span",{staticClass:"line-number"},[s._v("46")]),n("br"),n("span",{staticClass:"line-number"},[s._v("47")]),n("br"),n("span",{staticClass:"line-number"},[s._v("48")]),n("br"),n("span",{staticClass:"line-number"},[s._v("49")]),n("br"),n("span",{staticClass:"line-number"},[s._v("50")]),n("br"),n("span",{staticClass:"line-number"},[s._v("51")]),n("br"),n("span",{staticClass:"line-number"},[s._v("52")]),n("br"),n("span",{staticClass:"line-number"},[s._v("53")]),n("br"),n("span",{staticClass:"line-number"},[s._v("54")]),n("br"),n("span",{staticClass:"line-number"},[s._v("55")]),n("br"),n("span",{staticClass:"line-number"},[s._v("56")]),n("br"),n("span",{staticClass:"line-number"},[s._v("57")]),n("br"),n("span",{staticClass:"line-number"},[s._v("58")]),n("br"),n("span",{staticClass:"line-number"},[s._v("59")]),n("br"),n("span",{staticClass:"line-number"},[s._v("60")]),n("br"),n("span",{staticClass:"line-number"},[s._v("61")]),n("br"),n("span",{staticClass:"line-number"},[s._v("62")]),n("br"),n("span",{staticClass:"line-number"},[s._v("63")]),n("br"),n("span",{staticClass:"line-number"},[s._v("64")]),n("br"),n("span",{staticClass:"line-number"},[s._v("65")]),n("br"),n("span",{staticClass:"line-number"},[s._v("66")]),n("br"),n("span",{staticClass:"line-number"},[s._v("67")]),n("br"),n("span",{staticClass:"line-number"},[s._v("68")]),n("br"),n("span",{staticClass:"line-number"},[s._v("69")]),n("br")])]),n("hr"),s._v(" "),n("h2",{attrs:{id:"序列化类源码分析"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#序列化类源码分析"}},[s._v("#")]),s._v(" 序列化类源码分析")]),s._v(" "),n("h3",{attrs:{id:"ser-is-valid"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#ser-is-valid"}},[s._v("#")]),s._v(" ser.is_valid()")]),s._v(" "),n("blockquote",[n("p",[n("font",{attrs:{color:"brown"}},[n("strong",[s._v("反序列化的校验顺序:")])]),n("br"),s._v("\n     for 字段 in 字段们:"),n("br"),s._v("\n          字段自己的校验 - 字段局部钩子的校验"),n("br"),s._v(" "),n("strong",[s._v("最后")]),s._v(" 全局钩子的校验")],1),s._v(" "),n("p",[s._v("通过校验后,ser.is_valid()的值就为True, 校验不通过, 值为false, 校验不通过,会抛异常(drf的APIView会捕获全局异常)"),n("br"),s._v("\n校验通过,调用了ser.save().. 新增触发create,更新触发update. .  save()的源码分析前面有!")])]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[s._v("ser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" BookSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("request"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_valid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 校验字段是否合法!")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    校验了三个地方:字段本身有的(包括validators参数列表里指定的那些函数)、局部钩子、全局钩子")]),s._v("\n\nser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("is_valid"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" 按照查找规则"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("最终执行的是BaseSerializer类里的is_valid方法\nis_valid方法的源码如下"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("is_valid")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" raise_exception"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 断言不用看")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("assert")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("hasattr")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'initial_data'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- self是谁?Serializer类的实例化对象,这里是ser")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    刚开始的时候,ser里命名空间里是没有_validated_data这个键的,经过校验后才有的!!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    注意,重复多次校验,只会走一次.")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#        因为只要校验过一次,ser的命名空间里就有_validated_data这个key啦,其值是校验后的数据!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#        它就不会执行self._validated_data = self.run_validation(self.initial_data)啦!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#        直接return not bool(self._errors)")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("hasattr")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'_validated_data'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("try")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- ★")]),s._v("\n                self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_validated_data "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("run_validation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("initial_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("except")]),s._v(" ValidationError "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" exc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 捕获的异常可以通过 ser.error取出来,是一个字典!!")]),s._v("\n                errors"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("field_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" exc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("detail\n                "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 最终返回的是bool类型,校验成功返回True,失败返回False")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("bool")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("_errors"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n      \n      \n那 self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("run_validation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("initial_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 执行的是 谁"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v("哪个类 的run_validation方法?!\n★这里有个小坑"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("用pycharm直接 command"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v("b 跳转到的是Field类里的run_validation方法"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("因为BaseSerializer类继承了Field类"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n这样找是错的"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("应该重新按照查找规则开始查找 不要过于相信pycharm!!"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("つД`"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("ノ\n从sel"),n("span",{pre:!0,attrs:{class:"token string-interpolation"}},[n("span",{pre:!0,attrs:{class:"token string"}},[s._v("f'这里是ser'")])]),s._v("所在类BookSerializer "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" Serializer "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" BaseSerializer "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" Field "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v("Object\n在Serializer类中找到了run_validation方法!!\n所以self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("run_validation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("initial_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" 执行的是Serializer类中的run_validation方法!!!\nrun_validation方法的源码如下"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("run_validation")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" data"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("empty"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("is_empty_value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("validate_empty_values"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" is_empty_value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" data\n\n        value "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("to_internal_value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 字段自己的规则以及局部钩子的校验!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("try")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("run_validators"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 执行全局钩子")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    若我们自定义的序列化类里写了validate方法!!执行它!")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    若没有,按照查找规则,会执行Serializer类里的validate方法!! - 直接返回attrs")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    def validate(self, attrs):")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#        return attrs")]),s._v("\n            value "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("validate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  \n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- assert 条件为false时抛出异常")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    这里是为了保证校验通过必须return attrs!!不然的话,默认return None.抛异常.")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("assert")]),s._v(" value "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("is")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'.validate() should return the validated data'")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 注意:在执行全局钩子时,出了异常抛出drf的ValidationError才会被捕获到!!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    这里的ValidationError是drf的;DjangoValidationError是Django的,它导进来时起了个别名.")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("except")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ValidationError"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" DjangoValidationError"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" exc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("raise")]),s._v(" ValidationError"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("detail"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("as_serializer_error"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("exc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" value\n\n\n局部钩子校验相关的to_internal_value方法的源码如下"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[s._v("to_internal_value")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("isinstance")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Mapping"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- fields就是自定义序列化类里那些要序列化的字段类!!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#    for循环一个个的判断!")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" field "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" fields"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- ★ 通过反射 看自定义序列化类里有没有 validate_字段名 的方法!!")]),s._v("\n            validate_method "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("getattr")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[s._v("'validate_'")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("field_name"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            primitive_value "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get_value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("try")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 校验字段自己的规则!")]),s._v("\n                validated_value "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" field"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("run_validation"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("primitive_value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 反射有的话,就会执行该局部钩子函数 validated_value参数就是我们钩子函数里的item参数")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" validate_method "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("is")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("not")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                    validated_value "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" validate_method"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("validated_value"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("except")]),s._v(" ValidationError "),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" exc"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n                "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n            "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br"),n("span",{staticClass:"line-number"},[s._v("45")]),n("br"),n("span",{staticClass:"line-number"},[s._v("46")]),n("br"),n("span",{staticClass:"line-number"},[s._v("47")]),n("br"),n("span",{staticClass:"line-number"},[s._v("48")]),n("br"),n("span",{staticClass:"line-number"},[s._v("49")]),n("br"),n("span",{staticClass:"line-number"},[s._v("50")]),n("br"),n("span",{staticClass:"line-number"},[s._v("51")]),n("br"),n("span",{staticClass:"line-number"},[s._v("52")]),n("br"),n("span",{staticClass:"line-number"},[s._v("53")]),n("br"),n("span",{staticClass:"line-number"},[s._v("54")]),n("br"),n("span",{staticClass:"line-number"},[s._v("55")]),n("br"),n("span",{staticClass:"line-number"},[s._v("56")]),n("br"),n("span",{staticClass:"line-number"},[s._v("57")]),n("br"),n("span",{staticClass:"line-number"},[s._v("58")]),n("br"),n("span",{staticClass:"line-number"},[s._v("59")]),n("br"),n("span",{staticClass:"line-number"},[s._v("60")]),n("br"),n("span",{staticClass:"line-number"},[s._v("61")]),n("br"),n("span",{staticClass:"line-number"},[s._v("62")]),n("br"),n("span",{staticClass:"line-number"},[s._v("63")]),n("br"),n("span",{staticClass:"line-number"},[s._v("64")]),n("br"),n("span",{staticClass:"line-number"},[s._v("65")]),n("br"),n("span",{staticClass:"line-number"},[s._v("66")]),n("br"),n("span",{staticClass:"line-number"},[s._v("67")]),n("br"),n("span",{staticClass:"line-number"},[s._v("68")]),n("br"),n("span",{staticClass:"line-number"},[s._v("69")]),n("br"),n("span",{staticClass:"line-number"},[s._v("70")]),n("br"),n("span",{staticClass:"line-number"},[s._v("71")]),n("br"),n("span",{staticClass:"line-number"},[s._v("72")]),n("br"),n("span",{staticClass:"line-number"},[s._v("73")]),n("br"),n("span",{staticClass:"line-number"},[s._v("74")]),n("br"),n("span",{staticClass:"line-number"},[s._v("75")]),n("br"),n("span",{staticClass:"line-number"},[s._v("76")]),n("br"),n("span",{staticClass:"line-number"},[s._v("77")]),n("br"),n("span",{staticClass:"line-number"},[s._v("78")]),n("br"),n("span",{staticClass:"line-number"},[s._v("79")]),n("br"),n("span",{staticClass:"line-number"},[s._v("80")]),n("br"),n("span",{staticClass:"line-number"},[s._v("81")]),n("br"),n("span",{staticClass:"line-number"},[s._v("82")]),n("br"),n("span",{staticClass:"line-number"},[s._v("83")]),n("br")])]),n("h3",{attrs:{id:"many参数"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#many参数"}},[s._v("#")]),s._v(" many参数")]),s._v(" "),n("div",{staticClass:"language-python line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 序列化多条")]),s._v("\nser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" BookSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("qs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" many"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("type")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# <class 'rest_framework.serializers.ListSerializer'>")]),s._v("\n                  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ListSerializer相当于一个列表,里面套了一个个BookSerializer的实例对象!")]),s._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 序列化单条")]),s._v("\nser "),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" BookSerializer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("instance"),n("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("book"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -- 默认many=False")]),s._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("type")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("ser"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),n("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# <class 'app01.serializer.BookSerializer'>")]),s._v("\n\n神奇吧!!ser不一定就是BookSerializer实例化的对象"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("是由many参数决定的!!\n如何办到的"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("这个涉及到元类啦!!不想深究"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("不清楚也不影响开发!!\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br")])]),n("hr")])}),[],!1,null,null,null);t.default=e.exports},772:function(s,t,a){s.exports=a.p+"assets/img/10.92e7e687.jpeg"},773:function(s,t,a){s.exports=a.p+"assets/img/11.f3220de9.png"}}]);